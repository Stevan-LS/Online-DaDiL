{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SL276123\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ot\\backend.py:2998: UserWarning: To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: \n",
      "from tensorflow.python.ops.numpy_ops import np_config\n",
      "np_config.enable_numpy_behavior()\n",
      "  register_backend(TensorflowBackend())\n",
      "C:\\Users\\SL276123\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Tests_ODaDiL import test_dadil, test_odadil, test_forgetting_odadil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = []\n",
    "for i in range(1, 11):\n",
    "    dataset = np.load(f'data/toy_non_linear_100d_dataset_{i}.npy')\n",
    "    list_of_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "batch_size = 200\n",
    "n_atoms = 3\n",
    "n_classes = 10\n",
    "n_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_dadil(list_of_datasets, n_samples, n_classes, n_atoms, batch_size, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin': {'wda': 0.6477999999999999,\n",
       "  'e': 0.5986,\n",
       "  'e_ot': 0.6491799999999999,\n",
       "  'r': 0.6237,\n",
       "  'r_ot': 0.5994999999999999},\n",
       " 'rbf': {'wda': 0.6413,\n",
       "  'e': 0.46840000000000004,\n",
       "  'e_ot': 0.6289300000000001,\n",
       "  'r': 0.4699000000000001,\n",
       "  'r_ot': 0.6618000000000002},\n",
       " 'RF': {'wda': 0.6448,\n",
       "  'e': 0.6533,\n",
       "  'e_ot': 0.5786400000000002,\n",
       "  'r': 0.6512,\n",
       "  'r_ot': 0.5767100000000001}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1\n",
      "It 1/100, Loss: 6144108.2\n",
      "It 2/100, Loss: 4108640.75\n",
      "It 3/100, Loss: 2760120.05\n",
      "It 4/100, Loss: 1932648.125\n",
      "It 5/100, Loss: 1672716.0\n",
      "It 6/100, Loss: 1536847.575\n",
      "It 7/100, Loss: 1446199.25\n",
      "It 8/100, Loss: 1419456.925\n",
      "It 9/100, Loss: 1391736.75\n",
      "It 10/100, Loss: 1380978.8000000003\n",
      "It 11/100, Loss: 1363171.35\n",
      "It 12/100, Loss: 1379249.75\n",
      "It 13/100, Loss: 1357000.625\n",
      "It 14/100, Loss: 1333794.65\n",
      "It 15/100, Loss: 1332724.9\n",
      "It 16/100, Loss: 1340062.3\n",
      "It 17/100, Loss: 1316250.5\n",
      "It 18/100, Loss: 1308938.225\n",
      "It 19/100, Loss: 1304073.2750000001\n",
      "It 20/100, Loss: 1291881.625\n",
      "It 21/100, Loss: 1285989.85\n",
      "It 22/100, Loss: 1271570.375\n",
      "It 23/100, Loss: 1275166.25\n",
      "It 24/100, Loss: 1267577.2\n",
      "It 25/100, Loss: 1260663.325\n",
      "It 26/100, Loss: 1251033.4999999998\n",
      "It 27/100, Loss: 1242089.3\n",
      "It 28/100, Loss: 1230373.875\n",
      "It 29/100, Loss: 1227022.1\n",
      "It 30/100, Loss: 1229320.0\n",
      "It 31/100, Loss: 1218587.875\n",
      "It 32/100, Loss: 1227353.775\n",
      "It 33/100, Loss: 1205188.35\n",
      "It 34/100, Loss: 1208392.35\n",
      "It 35/100, Loss: 1192634.2\n",
      "It 36/100, Loss: 1188494.625\n",
      "It 37/100, Loss: 1179373.925\n",
      "It 38/100, Loss: 1164971.475\n",
      "It 39/100, Loss: 1164385.1\n",
      "It 40/100, Loss: 1171839.45\n",
      "It 41/100, Loss: 1154290.475\n",
      "It 42/100, Loss: 1152495.875\n",
      "It 43/100, Loss: 1148411.7750000001\n",
      "It 44/100, Loss: 1143216.925\n",
      "It 45/100, Loss: 1133755.925\n",
      "It 46/100, Loss: 1134648.7750000001\n",
      "It 47/100, Loss: 1122600.6500000001\n",
      "It 48/100, Loss: 1108533.1749999998\n",
      "It 49/100, Loss: 1117232.7249999999\n",
      "It 50/100, Loss: 1103948.975\n",
      "It 51/100, Loss: 1087828.25\n",
      "It 52/100, Loss: 1098153.5\n",
      "It 53/100, Loss: 1092735.9000000001\n",
      "It 54/100, Loss: 1073092.8\n",
      "It 55/100, Loss: 1081147.15\n",
      "It 56/100, Loss: 1073427.825\n",
      "It 57/100, Loss: 1060239.1\n",
      "It 58/100, Loss: 1063759.1375\n",
      "It 59/100, Loss: 1040929.875\n",
      "It 60/100, Loss: 1041524.2250000001\n",
      "It 61/100, Loss: 1051015.6875\n",
      "It 62/100, Loss: 1022402.45\n",
      "It 63/100, Loss: 1013683.4875\n",
      "It 64/100, Loss: 1029350.5625\n",
      "It 65/100, Loss: 1016495.65\n",
      "It 66/100, Loss: 1002984.5625\n",
      "It 67/100, Loss: 999321.95\n",
      "It 68/100, Loss: 996856.5375\n",
      "It 69/100, Loss: 977387.4625\n",
      "It 70/100, Loss: 970075.6375\n",
      "It 71/100, Loss: 967290.825\n",
      "It 72/100, Loss: 963122.5\n",
      "It 73/100, Loss: 961396.7124999999\n",
      "It 74/100, Loss: 958179.1875\n",
      "It 75/100, Loss: 948320.7749999999\n",
      "It 76/100, Loss: 925672.7625000001\n",
      "It 77/100, Loss: 934594.9624999999\n",
      "It 78/100, Loss: 924720.6499999999\n",
      "It 79/100, Loss: 930804.9125\n",
      "It 80/100, Loss: 930910.6\n",
      "It 81/100, Loss: 915320.7375\n",
      "It 82/100, Loss: 907696.55\n",
      "It 83/100, Loss: 912170.525\n",
      "It 84/100, Loss: 913123.5374999999\n",
      "It 85/100, Loss: 905799.8875000001\n",
      "It 86/100, Loss: 902803.9500000001\n",
      "It 87/100, Loss: 902533.4875\n",
      "It 88/100, Loss: 885750.1000000001\n",
      "It 89/100, Loss: 886940.35\n",
      "It 90/100, Loss: 873969.275\n",
      "It 91/100, Loss: 873210.5125\n",
      "It 92/100, Loss: 875068.5375000001\n",
      "It 93/100, Loss: 868146.275\n",
      "It 94/100, Loss: 867382.6125\n",
      "It 95/100, Loss: 870181.0625\n",
      "It 96/100, Loss: 862462.55\n",
      "It 97/100, Loss: 864275.9625\n",
      "It 98/100, Loss: 846864.825\n",
      "It 99/100, Loss: 839648.8374999999\n",
      "It 100/100, Loss: 839140.1875\n",
      "Loss: 107700.30156250001\n",
      "Loss: 110566.5328125\n",
      "Loss: 114620.74687500001\n",
      "Loss: 112477.1359375\n",
      "Loss: 108888.821875\n",
      "Loss: 109471.746875\n",
      "Loss: 99121.4953125\n",
      "Loss: 109074.50625\n",
      "Loss: 115498.409375\n",
      "Loss: 110141.09687499999\n",
      "Loss: 109240.9765625\n",
      "Loss: 103365.921875\n",
      "Loss: 99669.6296875\n",
      "Loss: 109286.5765625\n",
      "Loss: 116551.2390625\n",
      "Loss: 105365.99531249999\n",
      "Loss: 110593.76562500001\n",
      "Loss: 104029.2\n",
      "Loss: 110354.5625\n",
      "Loss: 110097.41875\n",
      "Loss: 107513.875\n",
      "Loss: 102970.1953125\n",
      "Loss: 111979.596875\n",
      "Loss: 111194.5984375\n",
      "Loss: 106279.97031250001\n",
      "Loss: 108840.8921875\n",
      "Loss: 102591.9109375\n",
      "Loss: 106519.82500000001\n",
      "Loss: 107887.13124999999\n",
      "Loss: 107704.2109375\n",
      "Loss: 103757.5140625\n",
      "Loss: 103408.778125\n",
      "Loss: 105618.85625\n",
      "Loss: 102070.921875\n",
      "Loss: 107822.22187499999\n",
      "Loss: 113036.8109375\n",
      "Loss: 112758.02656250002\n",
      "Loss: 104951.83437499999\n",
      "Loss: 105494.9703125\n",
      "Loss: 114239.59062500001\n",
      "Loss: 111855.82499999998\n",
      "Loss: 102006.3515625\n",
      "Loss: 103194.94687500001\n",
      "Loss: 108938.709375\n",
      "Loss: 108949.121875\n",
      "Loss: 106578.43437500001\n",
      "Loss: 108822.4125\n",
      "Loss: 109111.88437499998\n",
      "Loss: 108158.61250000002\n"
     ]
    }
   ],
   "source": [
    "before_online_results, after_online_results = test_forgetting_odadil([list_of_datasets[0]], n_samples, n_classes, n_atoms, batch_size, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin': {'r': [0.771, 0.785, 0.769, 0.793, 0.785],\n",
       "  'r_ot': [0.58,\n",
       "   0.5750000000000001,\n",
       "   0.5830000000000001,\n",
       "   0.5809999999999998,\n",
       "   0.566]},\n",
       " 'rbf': {'r': [0.396, 0.35, 0.401, 0.362, 0.347],\n",
       "  'r_ot': [0.75, 0.75, 0.726, 0.7590000000000001, 0.75]},\n",
       " 'RF': {'r': [0.791, 0.774, 0.79, 0.776, 0.764],\n",
       "  'r_ot': [0.564,\n",
       "   0.5629999999999998,\n",
       "   0.5629999999999998,\n",
       "   0.569,\n",
       "   0.5600000000000002]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_online_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin': {'r': [0.753, 0.786, 0.771, 0.794, 0.783],\n",
       "  'r_ot': [0.5839999999999999,\n",
       "   0.5780000000000001,\n",
       "   0.5839999999999999,\n",
       "   0.582,\n",
       "   0.572]},\n",
       " 'rbf': {'r': [0.405, 0.35, 0.403, 0.367, 0.347],\n",
       "  'r_ot': [0.7510000000000001,\n",
       "   0.7519999999999999,\n",
       "   0.75,\n",
       "   0.7590000000000001,\n",
       "   0.7489999999999999]},\n",
       " 'RF': {'r': [0.772, 0.767, 0.784, 0.784, 0.717],\n",
       "  'r_ot': [0.564,\n",
       "   0.5649999999999998,\n",
       "   0.5629999999999998,\n",
       "   0.5709999999999998,\n",
       "   0.561]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_online_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
