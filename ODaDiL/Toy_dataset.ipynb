{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydil.ot_utils.pot_utils import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(1, 11):\n",
    "    # Parameters\n",
    "    num_samples = 1000 #number of samples\n",
    "    n_classes = 10 #number of classes\n",
    "    n_dim = 3 #dimension of the initial space\n",
    "    n_dim_high = 100 #dimension of the final space\n",
    "    n_domains = 6 #number of domains\n",
    "\n",
    "    # Generate random means and covariances for each component\n",
    "    means = np.random.randn(n_classes, n_dim) * 10\n",
    "    covariances = []\n",
    "    for _ in range(n_classes):\n",
    "        rand_matrix = np.random.rand(n_dim, n_dim)\n",
    "        covariances.append(rand_matrix @ rand_matrix.T + 0.1 * np.eye(n_dim))\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    weights = np.random.rand(n_classes)\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    n_samples_comp = np.random.multinomial(num_samples, np.array(weights))\n",
    "\n",
    "    while 0 in n_samples_comp:\n",
    "        weights = np.random.rand(n_classes)\n",
    "        weights /= np.sum(weights)\n",
    "        n_samples_comp = np.random.multinomial(num_samples, np.array(weights))\n",
    "\n",
    "    def non_linear_array(x):\n",
    "        vec = np.array([x[0], x[1], x[2], x[0]*x[1], x[0]*x[2], x[1]*x[2]])\n",
    "        return vec\n",
    "\n",
    "    data_list = []\n",
    "    for k, (mean, covariance, sample) in enumerate(zip(means, covariances, n_samples_comp)):\n",
    "        array_3d = np.random.multivariate_normal(mean, covariance, int(sample))\n",
    "        array_non_linear = np.zeros((int(sample), 6)) # 6 car non linéarité (x, y, z, xy, xz, yz) \n",
    "        for i in range(int(sample)):\n",
    "            array_non_linear[i] = non_linear_array(array_3d[i])\n",
    "        features = np.dot(array_non_linear, np.random.rand(6, n_dim_high))\n",
    "        classes = k * np.ones(int(sample))\n",
    "        data_list.append(np.concatenate([features, classes.reshape(-1, 1)], axis=1))\n",
    "\n",
    "    data = np.vstack(data_list)\n",
    "    data_feat = data[:, :-1]\n",
    "    data_class = data[:, -1]\n",
    "\n",
    "    def generate_random_spd_matrix(n):\n",
    "        A = np.random.randn(n, n)\n",
    "        spd_matrix = np.dot(A, A.T)  # Ensure the matrix is symmetric\n",
    "        spd_matrix += np.eye(n) * 0.1  # Add a small multiple of the identity matrix for positive definiteness\n",
    "        spectral_radius = np.max(np.abs(np.linalg.eigvals(spd_matrix)))\n",
    "        if spectral_radius > 2:\n",
    "            spd_matrix /= (spectral_radius/2)\n",
    "        return spd_matrix\n",
    "\n",
    "    def affine_transformation(data_feat):\n",
    "        product_matrix = generate_random_spd_matrix(n_dim_high)\n",
    "        sum_vector = np.random.randn(1, n_dim_high)\n",
    "        new_data_feat = np.dot(data_feat, product_matrix) + sum_vector\n",
    "        return new_data_feat\n",
    "\n",
    "    domains = [data]\n",
    "    for i in range(n_domains-1):\n",
    "        new_data_feat = affine_transformation(data_feat)\n",
    "        for c in range(n_classes):\n",
    "            ind_c = np.where(data_class == c)[0]\n",
    "            t_c = np.random.rand()\n",
    "            new_data_feat[ind_c] = t_c * new_data_feat[ind_c]\n",
    "        new_data = np.concatenate((new_data_feat, data_class.reshape(-1, 1)), axis=1)\n",
    "        domains.append(new_data)\n",
    "\n",
    "    toy_dataset = np.concatenate((domains[0], np.zeros((domains[0].shape[0], 1))), axis=1)\n",
    "\n",
    "    for i in range(1, len(domains)):\n",
    "        data_to_concatenate = np.concatenate((domains[i], i * np.ones((domains[0].shape[0], 1))), axis=1)\n",
    "        toy_dataset = np.concatenate((toy_dataset, data_to_concatenate), axis=0)\n",
    "\n",
    "np.save(f'toy_non_linear_100d_dataset_{it}.npy', toy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "target = 'C'\n",
    "with open(os.path.join('data', 'mlp_fts_256_target_{}.pkl'.format(target)), 'rb') as f:\n",
    "        dataset = pickle.loads(f.read())\n",
    "\n",
    "Xs, ys = [], []\n",
    "d = None\n",
    "keys = list(dataset.keys())\n",
    "for i in [0, 1]:\n",
    "    features = dataset[keys[i]]['Features']\n",
    "    labels = dataset[keys[i]]['Labels'].argmax(dim=1)\n",
    "    domain = i*np.ones((features.shape[0], 1))\n",
    "    Xs.append(features.float())\n",
    "    ys.append(labels.float())\n",
    "    if d is None:\n",
    "        d = domain\n",
    "    else:\n",
    "        d = np.concatenate([d, domain], axis=0)\n",
    "\n",
    "Xt = dataset[target]['fold 0']['Train']['Features'].float()\n",
    "yt = dataset[target]['fold 0']['Train']['Labels'].float().argmax(dim=1)\n",
    "\n",
    "Xt_test = dataset[target]['fold 0']['Test']['Features'].float()\n",
    "yt_test = dataset[target]['fold 0']['Test']['Labels'].float().argmax(dim=1)\n",
    "d = np.concatenate([d, 2*np.ones((Xt.shape[0], 1))], axis=0)\n",
    "\n",
    "n_domains = int(np.max(d)) + 1\n",
    "n_features = Xt.shape[1]\n",
    "n_classes = int(np.max(yt.numpy())) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skdim\n",
    "import numpy as np\n",
    "\n",
    "#estimate global intrinsic dimension\n",
    "#danco = skdim.id.DANCo().fit(Xt_test.numpy())\n",
    "#estimate local intrinsic dimension (dimension in k-nearest-neighborhoods around each point):\n",
    "lpca = skdim.id.lPCA().fit_pw(Xt.numpy(),\n",
    "                              n_neighbors = 100,\n",
    "                              n_jobs = 1)\n",
    "\n",
    "#get estimated intrinsic dimension\n",
    "#print(danco.dimension_)\n",
    "np.mean(lpca.dimension_pw_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
